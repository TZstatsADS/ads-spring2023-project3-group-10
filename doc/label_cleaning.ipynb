{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/train_dat/train_data.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/drive/MyDrive/train_dat')"
      ],
      "metadata": {
        "id": "hG0zf8Ce7CeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud0xje3E6_CL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example image plot\n",
        "img1 = cv2.imread('/content/drive/MyDrive/train_dat/images/{:05d}.png'.format(1))\n",
        "plt.imshow(img1)\n",
        "plt.xticks([]) ## remove the ticks on x-axis\n",
        "plt.yticks([]) ## remove the ticks on y-axis\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "FwXpFR75oC_g",
        "outputId": "509283c8-f775-4635-ecf4-68a2af812935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "noisy = pd.read_csv('/content/drive/MyDrive/train_dat/noisy_labels.csv',header=None)\n",
        "clean = pd.read_csv('/content/drive/MyDrive/train_dat/clean_labels.csv',header=None)\n"
      ],
      "metadata": {
        "id": "_X0efTWGBJed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "for i in range(1,10001):\n",
        "  images.append(cv2.imread('/content/drive/MyDrive/train_dat/images/{:05d}.png'.format(i)))\n",
        "  if i % 1000 == 0:\n",
        "    print(i)\n",
        "images = torch.Tensor(np.stack(images))"
      ],
      "metadata": {
        "id": "vUOD7vT9BXcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sz = 50\n",
        "images_trainloader = torch.utils.data.DataLoader(images[:6000], batch_size=sz)\n",
        "noisylabel_trainloader = torch.utils.data.DataLoader(nn.functional.one_hot(torch.Tensor(noisy[0].iloc[:6000].values).long()), batch_size=sz)\n",
        "label_trainloader = torch.utils.data.DataLoader(nn.functional.one_hot(torch.Tensor(clean[0].iloc[:6000].values).long()), batch_size=sz)\n",
        "\n",
        "images_valoader = torch.utils.data.DataLoader(images[6000:8000], batch_size=sz)\n",
        "noisylabel_valoader = torch.utils.data.DataLoader(nn.functional.one_hot(torch.Tensor(noisy[0].iloc[6000:8000].values).long()), batch_size=sz)\n",
        "label_valoader = torch.utils.data.DataLoader(nn.functional.one_hot(torch.Tensor(clean[0].iloc[6000:8000].values).long()), batch_size=sz)\n",
        "\n",
        "images_testloader = torch.utils.data.DataLoader(images[8000:10000], batch_size=sz)\n",
        "noisylabel_testloader = torch.utils.data.DataLoader(nn.functional.one_hot(torch.Tensor(noisy[0].iloc[8000:10].values).long()), batch_size=sz)\n",
        "label_testloader = torch.utils.data.DataLoader(nn.functional.one_hot(torch.Tensor(clean[0].iloc[6000:8000].values).long()), batch_size=sz)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXdDVALVSZ27",
        "outputId": "759aef26-f8e7-4a95-e87b-9b03f61dcd63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6000, 32, 32, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCNN(nn.Module):\n",
        "    def __init__(self,num_class):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8 + num_class, 64)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, num_class)\n",
        "        self.sm1 = nn.Softmax(1)\n",
        "        self.num_class = num_class\n",
        "\n",
        "    def forward(self, x,y):\n",
        "        y = torch.Tensor(y)\n",
        "        \n",
        "        x = x.permute(0,3,1,2)\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        \n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        \n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = x.reshape(x.shape[0],32*8*8)\n",
        "        # print(x.shape,torch.Tensor(y).shape)\n",
        "        x = torch.cat((x, y), dim=1)\n",
        "        \n",
        "        x = x.reshape(-1, 32 * 8 * 8 + self.num_class)\n",
        "        x = self.fc1(x.float())\n",
        "        \n",
        "        x = self.bn3(x)\n",
        "        \n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sm1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "model = MyCNN(nclass)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "# number of epochs to run\n",
        "# num_epochs = 5\n",
        "# for epoch in range(num_epochs):\n",
        "#     running_loss = 0.0\n",
        "#     for i, (d, nl, l) in enumerate(zip(trainloader,noisylabel_loader,label_loader),1):\n",
        "#         # print(\"LABELS\")\n",
        "#         # print(l)\n",
        "#         # inputs, labels = data\n",
        "#         # print(d.shape,nl.shape)\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(d,nl)\n",
        "#         loss = criterion(outputs, l) #.unsqueeze(0)\n",
        "\n",
        "#         # print(outputs,\"labels\",l)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         running_loss += loss.item()\n",
        "#         print(running_loss)\n",
        "#     print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, running_loss/len(trainloader)))\n"
      ],
      "metadata": {
        "id": "piMLiNuAK-Gd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "patience = 3\n",
        "best_val_loss = float('inf')\n",
        "epochs_since_improvement = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (d, nl, l) in enumerate(zip(images_trainloader, noisylabel_trainloader, label_trainloader), 1):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(d, nl)\n",
        "        loss = criterion(outputs, l)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print('Epoch [{}/{}], Training Loss: {:.4f}'.format(epoch+1, num_epochs, running_loss/len(trainloader)))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for j, (val_d, val_nl, val_l) in enumerate(zip(images_valoader, noisylabel_valoader, label_valoader), 1):\n",
        "            val_outputs = model(val_d, val_nl)\n",
        "            val_loss += criterion(val_outputs, val_l).item()\n",
        "            _, predicted = torch.max(val_outputs.data, 1)\n",
        "            _, gt = torch.max(val_l.data, 1)\n",
        "            total += val_l.size(0)\n",
        "            correct += (predicted == gt).sum().item()\n",
        "        val_loss /= len(images_valoader)\n",
        "        val_acc = 100 * correct / total\n",
        "        print('Epoch [{}/{}], Validation Loss: {:.4f}, Validation Accuracy: {:.2f}%'.format(epoch+1, num_epochs, val_loss, val_acc))\n",
        "    \n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "        epochs_since_improvement = 0\n",
        "    else:\n",
        "        epochs_since_improvement += 1\n",
        "        \n",
        "    if epochs_since_improvement > patience:\n",
        "        print('Stopping training after {} epochs without improvement'.format(epochs_since_improvement))\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nillOQagU8z",
        "outputId": "4a6340c8-8861-4229-c91e-1881f352c38d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Training Loss: 0.0048\n",
            "Epoch [1/50], Validation Loss: 0.1183, Validation Accuracy: 41.95%\n",
            "Epoch [2/50], Training Loss: 0.0048\n",
            "Epoch [2/50], Validation Loss: 0.1181, Validation Accuracy: 41.75%\n",
            "Epoch [3/50], Training Loss: 0.0047\n",
            "Epoch [3/50], Validation Loss: 0.1179, Validation Accuracy: 42.00%\n",
            "Epoch [4/50], Training Loss: 0.0047\n",
            "Epoch [4/50], Validation Loss: 0.1177, Validation Accuracy: 42.10%\n",
            "Epoch [5/50], Training Loss: 0.0047\n",
            "Epoch [5/50], Validation Loss: 0.1174, Validation Accuracy: 42.20%\n",
            "Epoch [6/50], Training Loss: 0.0046\n",
            "Epoch [6/50], Validation Loss: 0.1172, Validation Accuracy: 42.40%\n",
            "Epoch [7/50], Training Loss: 0.0046\n",
            "Epoch [7/50], Validation Loss: 0.1171, Validation Accuracy: 42.10%\n",
            "Epoch [8/50], Training Loss: 0.0046\n",
            "Epoch [8/50], Validation Loss: 0.1168, Validation Accuracy: 42.40%\n",
            "Epoch [9/50], Training Loss: 0.0046\n",
            "Epoch [9/50], Validation Loss: 0.1166, Validation Accuracy: 42.35%\n",
            "Epoch [10/50], Training Loss: 0.0045\n",
            "Epoch [10/50], Validation Loss: 0.1163, Validation Accuracy: 42.75%\n",
            "Epoch [11/50], Training Loss: 0.0045\n",
            "Epoch [11/50], Validation Loss: 0.1159, Validation Accuracy: 43.15%\n",
            "Epoch [12/50], Training Loss: 0.0045\n",
            "Epoch [12/50], Validation Loss: 0.1155, Validation Accuracy: 43.65%\n",
            "Epoch [13/50], Training Loss: 0.0044\n",
            "Epoch [13/50], Validation Loss: 0.1154, Validation Accuracy: 43.35%\n",
            "Epoch [14/50], Training Loss: 0.0044\n",
            "Epoch [14/50], Validation Loss: 0.1152, Validation Accuracy: 43.40%\n",
            "Epoch [15/50], Training Loss: 0.0044\n",
            "Epoch [15/50], Validation Loss: 0.1149, Validation Accuracy: 43.20%\n",
            "Epoch [16/50], Training Loss: 0.0043\n",
            "Epoch [16/50], Validation Loss: 0.1148, Validation Accuracy: 42.80%\n",
            "Epoch [17/50], Training Loss: 0.0043\n",
            "Epoch [17/50], Validation Loss: 0.1145, Validation Accuracy: 43.20%\n",
            "Epoch [18/50], Training Loss: 0.0043\n",
            "Epoch [18/50], Validation Loss: 0.1146, Validation Accuracy: 42.95%\n",
            "Epoch [19/50], Training Loss: 0.0043\n",
            "Epoch [19/50], Validation Loss: 0.1146, Validation Accuracy: 43.15%\n",
            "Epoch [20/50], Training Loss: 0.0042\n",
            "Epoch [20/50], Validation Loss: 0.1148, Validation Accuracy: 42.55%\n",
            "Epoch [21/50], Training Loss: 0.0042\n",
            "Epoch [21/50], Validation Loss: 0.1152, Validation Accuracy: 42.45%\n",
            "Stopping training after 4 epochs without improvement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on test set\n",
        "correct = 0\n",
        "total = 0\n",
        "for t, (t_d, t_nl, t_l) in enumerate(zip(images_testloader, noisylabel_testloader, label_testloader), 1):\n",
        "  test_outputs = model(t_d, t_nl)\n",
        "  # preds = torch.zeros_like(test_outputs).scatter_(1, torch.argmax(test_outputs, dim=1).unsqueeze(1), 1)\n",
        "  correct += sum(torch.argmax(test_outputs, dim=1) == torch.argmax(t_l, dim=1))\n",
        "  total += len(t_l)\n",
        "accuracy = correct / total\n",
        "print('Accuracy on the test set: %f' % (correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR7B9XEmYc3Q",
        "outputId": "b7aac8e4-44c8-48d6-ca5a-e18128511df1"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 0.428500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# benchmark\n",
        "np.mean(noisy[0][:10000] == clean[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbBisD_cio2K",
        "outputId": "380ca4b7-e353-4a7b-f6d4-9266da255884"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3968"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample data to test the network\n",
        "\n",
        "#noisylabel_loader\n",
        "# nn.functional.one_hot(torch.Tensor(noisy[0].iloc[:10000].values).long())\n",
        "#label_loader\n",
        "# nn.functional.one_hot(torch.Tensor(clean[0].values).long())\n",
        "\n",
        "import random\n",
        "# batch size 4\n",
        "sz = 4\n",
        "trainloader = torch.utils.data.DataLoader(torch.Tensor(np.random.rand(8,32,32,3)), batch_size=sz)\n",
        "# number of classes 10\n",
        "nclass = 10\n",
        "\n",
        "ys = np.zeros(shape=(8,nclass))\n",
        "for i in range(ys.shape[0]):\n",
        "  labs = np.zeros(nclass)\n",
        "  labs[random.randint(0,nclass-1)] = 1\n",
        "  ys[i] = labs\n",
        "noisylabel_loader = torch.utils.data.DataLoader(ys, batch_size=sz)\n",
        "\n",
        "ys = np.zeros(shape=(8,nclass))\n",
        "for i in range(ys.shape[0]):\n",
        "  labs = np.zeros(nclass)\n",
        "  labs[random.randint(0,nclass-1)] = 1\n",
        "  ys[i] = labs\n",
        "label_loader = torch.utils.data.DataLoader(ys, batch_size=sz)\n",
        "\n",
        "for i, (d, nl, l) in enumerate(zip(trainloader,noisylabel_loader,label_loader),0):\n",
        "  print(i,d.shape,nl.shape,l.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkFhSjE3RUEo",
        "outputId": "f49721be-3ab3-4627-c4d6-f1fa395db97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([4, 32, 32, 3]) torch.Size([4, 10]) torch.Size([4, 10])\n",
            "1 torch.Size([4, 32, 32, 3]) torch.Size([4, 10]) torch.Size([4, 10])\n"
          ]
        }
      ]
    }
  ]
}